{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e64d13",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.11.0)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/2025/CURSOS UNMSM/CICLO 8/SI/SI - PROYECTO FINAL/SistemaInteligentedePredicci-ndeRiego/venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8ed753",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.11.0)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/2025/CURSOS UNMSM/CICLO 8/SI/SI - PROYECTO FINAL/SistemaInteligentedePredicci-ndeRiego/venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Librer√≠as de Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score,\n",
    "                             precision_score, recall_score, f1_score, roc_auc_score,\n",
    "                             roc_curve, precision_recall_curve, average_precision_score)\n",
    "\n",
    "# Modelos de Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier,\n",
    "                               AdaBoostClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# SMOTE para balanceo de clases\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FASE 1: COMPRENSI√ìN DEL NEGOCIO (Business Understanding)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "OBJETIVO: Predecir el resultado (√©xito/fracaso) de cultivos bas√°ndose en:\n",
    "- Tipo de cultivo (crop ID)\n",
    "- Tipo de suelo (soil_type)\n",
    "- Etapa de pl√°ntula (Seedling Stage)\n",
    "- MOI (√çndice de humedad del suelo)\n",
    "- Temperatura\n",
    "- Humedad ambiental\n",
    "\n",
    "PROBLEMA: Clasificaci√≥n binaria (result: 0 = fracaso, 1 = √©xito)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FASE 2: COMPRENSI√ìN DE LOS DATOS (Data Understanding)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Definir la ruta base\n",
    "BASE = Path(\"C:/2025/CURSOS UNMSM/CICLO 8/SI/SI - PROYECTO FINAL/SistemaInteligentedePredicci-ndeRiego\")\n",
    "visual_dir = BASE / \"visualizaciones1\"\n",
    "models_dir = BASE / \"modelos_guardados\"\n",
    "\n",
    "# Crear carpetas si no existen\n",
    "visual_dir.mkdir(parents=True, exist_ok=True)\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Ruta del archivo\n",
    "archivo_nombre = BASE / \"dataSalvadora.xlsx\"\n",
    "\n",
    "# Leer el archivo Excel\n",
    "df = pd.read_excel(archivo_nombre)\n",
    "\n",
    "# Mostrar informaci√≥n del dataset\n",
    "print(f\"\\nüìä Dimensiones del dataset: {df.shape[0]} filas x {df.shape[1]} columnas\")\n",
    "print(f\"\\nüìã Columnas: {df.columns.tolist()}\")\n",
    "print(f\"\\nüîç Tipos de datos:\\n{df.dtypes}\")\n",
    "print(f\"\\nüìà Primeras filas del dataset:\")\n",
    "print(df.head(10))\n",
    "\n",
    "\n",
    "# Informaci√≥n estad√≠stica\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ESTAD√çSTICAS DESCRIPTIVAS\")\n",
    "print(\"=\"*80)\n",
    "print(df.describe())\n",
    "\n",
    "# Valores √∫nicos en variables categ√≥ricas\n",
    "print(\"\\nüìå Valores √∫nicos en variables categ√≥ricas:\")\n",
    "for col in ['crop ID', 'soil_type', 'Seedling Stage']:\n",
    "    print(f\"\\n{col}: {df[col].nunique()} valores √∫nicos\")\n",
    "    print(df[col].value_counts())\n",
    "\n",
    "# Distribuci√≥n de la variable objetivo\n",
    "print(\"\\nüéØ Distribuci√≥n de la variable objetivo (result):\")\n",
    "print(df['result'].value_counts())\n",
    "print(f\"\\nProporci√≥n:\")\n",
    "print(df['result'].value_counts(normalize=True))\n",
    "\n",
    "# Valores nulos\n",
    "print(\"\\n‚ùì Valores nulos por columna:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FASE 3: PREPARACI√ìN DE LOS DATOS (Data Preparation)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Copiar dataset original\n",
    "df_original = df.copy()\n",
    "\n",
    "# 3.1 Limpieza de datos\n",
    "print(\"\\nüßπ Paso 3.1: Limpieza de datos\")\n",
    "print(f\"\\nOutliers detectados en humidity: {len(df[df['humidity'] > 200])} registros\")\n",
    "print(f\"Rango actual de humidity: [{df['humidity'].min()}, {df['humidity'].max()}]\")\n",
    "\n",
    "# Limitar humidity a valores razonables (0-100%)\n",
    "df['humidity_cleaned'] = df['humidity'].clip(upper=100)\n",
    "print(f\"Rango corregido de humidity: [{df['humidity_cleaned'].min()}, {df['humidity_cleaned'].max()}]\")\n",
    "\n",
    "# 3.2 Codificaci√≥n de variables categ√≥ricas\n",
    "print(\"\\nüî§ Paso 3.2: Codificaci√≥n de variables categ√≥ricas\")\n",
    "\n",
    "# Label Encoding para variables categ√≥ricas\n",
    "le_crop = LabelEncoder()\n",
    "le_soil = LabelEncoder()\n",
    "le_seedling = LabelEncoder()\n",
    "\n",
    "df['crop_encoded'] = le_crop.fit_transform(df['crop ID'])\n",
    "df['soil_encoded'] = le_soil.fit_transform(df['soil_type'])\n",
    "df['seedling_encoded'] = le_seedling.fit_transform(df['Seedling Stage'])\n",
    "\n",
    "# 3.3 Ingenier√≠a de caracter√≠sticas\n",
    "print(\"\\n‚öôÔ∏è Paso 3.3: Ingenier√≠a de caracter√≠sticas\")\n",
    "\n",
    "df['temp_humidity_ratio'] = df['temp'] / (df['humidity_cleaned'] + 1)\n",
    "df['moi_temp_interaction'] = df['MOI'] * df['temp']\n",
    "df['temp_squared'] = df['temp'] ** 2\n",
    "df['humidity_squared'] = df['humidity_cleaned'] ** 2\n",
    "df['moi_squared'] = df['MOI'] ** 2\n",
    "\n",
    "print(\"Nuevas caracter√≠sticas creadas:\")\n",
    "print(\"- temp_humidity_ratio: Relaci√≥n temperatura/humedad\")\n",
    "print(\"- moi_temp_interaction: Interacci√≥n MOI x temperatura\")\n",
    "print(\"- temp_squared, humidity_squared, moi_squared: T√©rminos cuadr√°ticos\")\n",
    "\n",
    "# Seleccionar caracter√≠sticas finales\n",
    "feature_cols = ['crop_encoded', 'soil_encoded', 'seedling_encoded', 'MOI', \n",
    "                'temp', 'humidity_cleaned', 'temp_humidity_ratio', \n",
    "                'moi_temp_interaction', 'temp_squared', 'humidity_squared', 'moi_squared']\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df['result']\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset preparado con {X.shape[1]} caracter√≠sticas\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPLORACI√ìN VISUAL DE DATOS (EDA)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Matriz de correlaci√≥n\n",
    "plt.figure(figsize=(14, 10))\n",
    "correlation_matrix = df[['MOI', 'temp', 'humidity_cleaned', 'result', \n",
    "                         'temp_humidity_ratio', 'moi_temp_interaction']].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Matriz de Correlaci√≥n', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Distribuci√≥n de la variable objetivo\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "df['result'].value_counts().plot(kind='bar', ax=axes[0], color=['#e74c3c', '#2ecc71'])\n",
    "axes[0].set_title('Distribuci√≥n de Result (Conteo)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Result')\n",
    "axes[0].set_ylabel('Frecuencia')\n",
    "axes[0].set_xticklabels(['Fracaso (0)', '√âxito (1)'], rotation=0)\n",
    "\n",
    "df['result'].value_counts(normalize=True).plot(kind='pie', ax=axes[1], \n",
    "                                                autopct='%1.1f%%', \n",
    "                                                colors=['#e74c3c', '#2ecc71'])\n",
    "axes[1].set_title('Proporci√≥n de Result', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FASE 4: MODELADO (Modeling)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Divisi√≥n del dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                      random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\nüìä Tama√±o del conjunto de entrenamiento: {X_train.shape[0]} muestras\")\n",
    "print(f\"üìä Tama√±o del conjunto de prueba: {X_test.shape[0]} muestras\")\n",
    "\n",
    "# Escalado de caracter√≠sticas\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Verificar si se necesita SMOTE\n",
    "class_distribution = y_train.value_counts()\n",
    "minority_class = class_distribution.min()\n",
    "majority_class = class_distribution.max()\n",
    "imbalance_ratio = majority_class / minority_class\n",
    "\n",
    "print(f\"\\n‚öñÔ∏è Ratio de desbalanceo: {imbalance_ratio:.2f}\")\n",
    "use_smote = imbalance_ratio > 1.5\n",
    "\n",
    "if use_smote:\n",
    "    print(\"‚úÖ Aplicando SMOTE para balancear las clases...\")\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "    print(f\"Distribuci√≥n despu√©s de SMOTE: {pd.Series(y_train_resampled).value_counts()}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No se requiere SMOTE\")\n",
    "    X_train_resampled = X_train_scaled\n",
    "    y_train_resampled = y_train\n",
    "\n",
    "# Entrenamiento de modelos\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENTRENAMIENTO DE MODELOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss'),\n",
    "    'SVM': SVC(probability=True, random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "}\n",
    "\n",
    "# Evaluar y almacenar resultados\n",
    "results = []\n",
    "trained_models = {}\n",
    "\n",
    "# Entrenamiento y evaluaci√≥n de los modelos\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîÑ Entrenando {name}...\")\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    if y_pred_proba is not None:\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        avg_precision = average_precision_score(y_test, y_pred_proba)\n",
    "    else:\n",
    "        roc_auc = np.nan\n",
    "        avg_precision = np.nan\n",
    "    \n",
    "    cv_scores = cross_val_score(model, X_train_resampled, y_train_resampled, \n",
    "                                cv=5, scoring='accuracy')\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'ROC-AUC': roc_auc,\n",
    "        'Avg_Precision': avg_precision,\n",
    "        'CV_Mean': cv_mean,\n",
    "        'CV_Std': cv_std\n",
    "    })\n",
    "    \n",
    "    trained_models[name] = {\n",
    "        'model': model,\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_pred_proba\n",
    "    }\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTADOS DE TODOS LOS MODELOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('F1-Score', ascending=False)\n",
    "print(\"\\nüìä Comparaci√≥n de modelos (ordenados por F1-Score):\\n\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Visualizaci√≥n de comparaci√≥n de modelos\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Accuracy\n",
    "results_df.sort_values('Accuracy').plot(x='Model', y='Accuracy', kind='barh', \n",
    "                                        ax=axes[0,0], color='skyblue', legend=False)\n",
    "axes[0,0].set_title('Accuracy por Modelo', fontsize=14, fontweight='bold')\n",
    "axes[0,0].set_xlabel('Accuracy')\n",
    "\n",
    "# F1-Score\n",
    "results_df.sort_values('F1-Score').plot(x='Model', y='F1-Score', kind='barh', \n",
    "                                        ax=axes[0,1], color='lightcoral', legend=False)\n",
    "axes[0,1].set_title('F1-Score por Modelo', fontsize=14, fontweight='bold')\n",
    "axes[0,1].set_xlabel('F1-Score')\n",
    "\n",
    "# Precision\n",
    "results_df.sort_values('Precision').plot(x='Model', y='Precision', kind='barh', \n",
    "                                         ax=axes[1,0], color='lightgreen', legend=False)\n",
    "axes[1,0].set_title('Precision por Modelo', fontsize=14, fontweight='bold')\n",
    "axes[1,0].set_xlabel('Precision')\n",
    "\n",
    "# Recall\n",
    "results_df.sort_values('Recall').plot(x='Model', y='Recall', kind='barh', \n",
    "                                      ax=axes[1,1], color='plum', legend=False)\n",
    "axes[1,1].set_title('Recall por Modelo', fontsize=14, fontweight='bold')\n",
    "axes[1,1].set_xlabel('Recall')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISIS DEL MEJOR MODELO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Identificar el mejor modelo\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_model_info = trained_models[best_model_name]\n",
    "best_model = best_model_info['model']\n",
    "best_predictions = best_model_info['predictions']\n",
    "best_probabilities = best_model_info['probabilities']\n",
    "\n",
    "print(f\"\\nüèÜ MEJOR MODELO: {best_model_name}\")\n",
    "print(f\"\\nüìä M√âTRICAS DEL MEJOR MODELO:\")\n",
    "print(\"=\"*50)\n",
    "best_metrics = results_df.iloc[0]\n",
    "print(f\"Accuracy:        {best_metrics['Accuracy']:.4f}\")\n",
    "print(f\"Precision:       {best_metrics['Precision']:.4f}\")\n",
    "print(f\"Recall:          {best_metrics['Recall']:.4f}\")\n",
    "print(f\"F1-Score:        {best_metrics['F1-Score']:.4f}\")\n",
    "print(f\"ROC-AUC:         {best_metrics['ROC-AUC']:.4f}\")\n",
    "print(f\"Avg Precision:   {best_metrics['Avg_Precision']:.4f}\")\n",
    "print(f\"CV Mean:         {best_metrics['CV_Mean']:.4f}\")\n",
    "print(f\"CV Std:          {best_metrics['CV_Std']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"REPORTE DE CLASIFICACI√ìN DETALLADO\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(y_test, best_predictions, \n",
    "                          target_names=['Fracaso (0)', '√âxito (1)']))\n",
    "\n",
    "# Matriz de Confusi√≥n\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MATRIZ DE CONFUSI√ìN\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "cm = confusion_matrix(y_test, best_predictions)\n",
    "print(cm)\n",
    "\n",
    "# Visualizaci√≥n de la Matriz de Confusi√≥n\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Matriz de confusi√≥n con valores absolutos\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0], \n",
    "            xticklabels=['Fracaso (0)', '√âxito (1)'], \n",
    "            yticklabels=['Fracaso (0)', '√âxito (1)'],\n",
    "            cbar_kws={\"shrink\": 0.8})\n",
    "axes[0].set_title(f'Matriz de Confusi√≥n - {best_model_name}\\n(Valores Absolutos)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Valor Real')\n",
    "axes[0].set_xlabel('Valor Predicho')\n",
    "\n",
    "# Matriz de confusi√≥n normalizada\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Greens', ax=axes[1],\n",
    "            xticklabels=['Fracaso (0)', '√âxito (1)'], \n",
    "            yticklabels=['Fracaso (0)', '√âxito (1)'],\n",
    "            cbar_kws={\"shrink\": 0.8})\n",
    "axes[1].set_title(f'Matriz de Confusi√≥n - {best_model_name}\\n(Normalizada)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Valor Real')\n",
    "axes[1].set_xlabel('Valor Predicho')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interpretaci√≥n de la matriz de confusi√≥n\n",
    "print(\"\\nüìä INTERPRETACI√ìN DE LA MATRIZ DE CONFUSI√ìN:\")\n",
    "print(\"=\"*50)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"‚úÖ Verdaderos Negativos (TN): {tn} - Fracasos correctamente predichos\")\n",
    "print(f\"‚ùå Falsos Positivos (FP): {fp} - Fracasos predichos como √©xitos\")\n",
    "print(f\"‚ùå Falsos Negativos (FN): {fn} - √âxitos predichos como fracasos\")\n",
    "print(f\"‚úÖ Verdaderos Positivos (TP): {tp} - √âxitos correctamente predichos\")\n",
    "\n",
    "# Curvas ROC y Precision-Recall si hay probabilidades\n",
    "if best_probabilities is not None:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Curva ROC\n",
    "    fpr, tpr, _ = roc_curve(y_test, best_probabilities)\n",
    "    roc_auc = roc_auc_score(y_test, best_probabilities)\n",
    "    \n",
    "    axes[0].plot(fpr, tpr, color='darkorange', lw=2, \n",
    "                label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    axes[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
    "    axes[0].set_xlim([0.0, 1.0])\n",
    "    axes[0].set_ylim([0.0, 1.05])\n",
    "    axes[0].set_xlabel('False Positive Rate')\n",
    "    axes[0].set_ylabel('True Positive Rate')\n",
    "    axes[0].set_title(f'Curva ROC - {best_model_name}', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend(loc=\"lower right\")\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    # Curva Precision-Recall\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_test, best_probabilities)\n",
    "    avg_precision = average_precision_score(y_test, best_probabilities)\n",
    "    \n",
    "    axes[1].plot(recall_vals, precision_vals, color='blue', lw=2,\n",
    "                label=f'PR curve (AP = {avg_precision:.4f})')\n",
    "    axes[1].set_xlim([0.0, 1.0])\n",
    "    axes[1].set_ylim([0.0, 1.05])\n",
    "    axes[1].set_xlabel('Recall')\n",
    "    axes[1].set_ylabel('Precision')\n",
    "    axes[1].set_title(f'Curva Precision-Recall - {best_model_name}', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "    axes[1].legend(loc=\"lower left\")\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ AN√ÅLISIS COMPLETADO\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüéØ El mejor modelo es: {best_model_name}\")\n",
    "print(f\"üìä Con un F1-Score de: {best_metrics['F1-Score']:.4f}\")\n",
    "print(f\"üéØ Y una Accuracy de: {best_metrics['Accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da6ca51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
